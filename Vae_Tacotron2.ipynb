{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Vae_Tacotron2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKSWH9LVKI8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "41aa3cea-7f57-4fb5-bf2c-c5e84fc6a681"
      },
      "source": [
        "!git clone https:///gilmoore:6Xgithub42@github.com/gilmoore/VAE_Tacotron2.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'VAE_Tacotron2'...\n",
            "warning: redirecting to https://gilmoore:6Xgithub42@github.com/gilmoore/VAE_Tacotron2.git/\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 49 (delta 6), reused 41 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tPW8JqtKlcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f66c4b7a-1cb1-44e4-af14-fa95ba4e6fd5"
      },
      "source": [
        "!ls -l "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Dec 18 16:52 sample_data\n",
            "drwxr-xr-x 5 root root 4096 Jan 10 11:19 VAE_Tacotron2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c0mdxi4KI88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00df7fe7-8053-4123-f285-358dd4dedcd0"
      },
      "source": [
        "cd VAE_Tacotron2\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/VAE_Tacotron2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_8eSy6KK14u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "90bd8acf-a030-4c8f-9112-5cbb42faec20"
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: falcon==1.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: inflect==0.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: librosa==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.5.1)\n",
            "Requirement already satisfied: matplotlib==2.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Collecting numpy==1.13.0\n",
            "  Using cached https://files.pythonhosted.org/packages/f8/ce/70cbaf09bdba60b624bb609fa53f7c4e2a0ea4b3c24132e934274d596121/numpy-1.13.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: scipy==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: tqdm==4.11.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (4.11.2)\n",
            "Requirement already satisfied: Unidecode==0.4.20 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.4.20)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from falcon==1.2.0->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: python-mimeparse>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from falcon==1.2.0->-r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 3)) (4.4.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 3)) (2.1.8)\n",
            "Requirement already satisfied: scikit-learn>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 3)) (0.22.1)\n",
            "Requirement already satisfied: resampy>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 3)) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 3)) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.2->-r requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.2->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.2->-r requirements.txt (line 4)) (2.4.6)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy>=0.1.2->librosa==0.5.1->-r requirements.txt (line 3)) (0.47.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy>=0.1.2->librosa==0.5.1->-r requirements.txt (line 3)) (42.0.2)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy>=0.1.2->librosa==0.5.1->-r requirements.txt (line 3)) (0.31.0)\n",
            "\u001b[31mERROR: xarray 0.14.1 has requirement numpy>=1.14, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement numpy<2.0,>=1.16.0, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.1.9 has requirement numpy>=1.15.0, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pywavelets 1.1.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 0.14.1 has requirement numpy>=1.14, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 0.25.3 has requirement numpy>=1.13.3, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement librosa>=0.6.2, but you'll have librosa 0.5.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement tqdm>=4.19.2, but you'll have tqdm 4.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement numpy>=1.15, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.25 has requirement numpy>=1.15, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.25 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.0 has requirement numpy>=1.16, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.1\n",
            "    Uninstalling numpy-1.18.1:\n",
            "      Successfully uninstalled numpy-1.18.1\n",
            "Successfully installed numpy-1.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tyUGwi3K4KH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e2a47da7-c96e-4d84-ae95-26be7ee9a4e7"
      },
      "source": [
        "\n",
        "!curl -O https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "#unzip LJspeech\n",
        "!tar xjf LJSpeech-1.1.tar.bz2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2621M  100 2621M    0     0  37.0M      0  0:01:10  0:01:10 --:--:-- 19.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u5vA5Z2SazH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3f976361-dbbf-4e48-92c1-5a440fcc3e74"
      },
      "source": [
        "!python -m pip install --upgrade pip"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAL4_DCYTTGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "b8d59019-e06c-4bbe-fd6c-9d02e01e3ea0"
      },
      "source": [
        "!pip uninstall numpy\n",
        "!pip install numpy"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling numpy-1.18.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.6\n",
            "    /usr/local/lib/python3.6/dist-packages/numpy-1.18.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/numpy/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled numpy-1.18.1\n",
            "Collecting numpy\n",
            "  Using cached https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement librosa>=0.6.2, but you'll have librosa 0.5.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement tqdm>=4.19.2, but you'll have tqdm 4.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.25 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.18.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-I3aPwBPFA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "ff67c9ef-ea84-4b4b-e06d-7e8af211ac2f"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "1.18.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jet1i8RuToWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e5f6374-fc5c-4d79-de53-cca48a01a0b3"
      },
      "source": [
        "cd VAE_Tacotron2/\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/VAE_Tacotron2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6J-V_UL8ni8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "e10b9155-c3b9-4e58-bc5a-a7cec456fea6"
      },
      "source": [
        "from datasets import preprocessor"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeazTjlX8xt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uegehMSLx4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8c87439a-5131-49d8-987d-9a47c2609cf2"
      },
      "source": [
        "!python preprocess.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "initializing preprocessing..\n",
            "Selecting data folders..\n",
            "100% 13100/13100 [27:51<00:00,  7.84it/s]\n",
            "Write 13100 utterances, 7422474 mel frames, 1920274688 audio timesteps, (24.19 hours)\n",
            "Max input length (text chars): 187\n",
            "Max mel frames length: 870\n",
            "Max audio timesteps length: 224256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQcGn1epDyMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "babe9f30-70c5-42cb-f39a-674fcda0f50a"
      },
      "source": [
        "pip install unidecode"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 4.8MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-gx636wDp28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tacotron.train import tacotron_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbPmBVv0MvHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84f9fd42-44e6-4fa2-c6df-78ba10664fbc"
      },
      "source": [
        "!python train.py --model='Tacotron'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Checkpoint path: ./logs-Tacotron/pretrained/model.ckpt\n",
            "Loading training data from: ./training_data/train.txt\n",
            "Using model: Tacotron\n",
            "Hyperparameters:\n",
            "  allow_clipping_in_normalization: True\n",
            "  attention_dim: 128\n",
            "  attention_filters: 32\n",
            "  attention_kernel: (31,)\n",
            "  cleaners: english_cleaners\n",
            "  cumulative_weights: True\n",
            "  decoder_layers: 2\n",
            "  decoder_lstm_units: 1024\n",
            "  embedding_dim: 512\n",
            "  enc_conv_channels: 512\n",
            "  enc_conv_kernel_size: (5,)\n",
            "  enc_conv_num_layers: 3\n",
            "  encoder_depth: 512\n",
            "  encoder_lstm_units: 256\n",
            "  fft_size: 1024\n",
            "  filters: [32, 32, 64, 64, 128, 128]\n",
            "  fmax: 7600\n",
            "  fmin: 125\n",
            "  frame_shift_ms: None\n",
            "  griffin_lim_iters: 60\n",
            "  hop_size: 256\n",
            "  impute_finished: False\n",
            "  init_vae_weights: 0.001\n",
            "  input_type: mulaw-quantize\n",
            "  log_scale_min: -32.23619130191664\n",
            "  mask_encoder: False\n",
            "  mask_finished: False\n",
            "  max_abs_value: 4.0\n",
            "  max_iters: 2500\n",
            "  mel_normalization: False\n",
            "  min_level_db: -100\n",
            "  num_freq: 513\n",
            "  num_mels: 80\n",
            "  outputs_per_step: 1\n",
            "  postnet_channels: 512\n",
            "  postnet_kernel_size: (5,)\n",
            "  postnet_num_layers: 5\n",
            "  power: 1.55\n",
            "  predict_linear: False\n",
            "  prenet_layers: [256, 256]\n",
            "  quantize_channels: 256\n",
            "  ref_level_db: 20\n",
            "  rescale: True\n",
            "  rescaling_max: 0.999\n",
            "  sample_rate: 22050\n",
            "  signal_normalization: True\n",
            "  silence_threshold: 2\n",
            "  smoothing: False\n",
            "  stop_at_any: True\n",
            "  symmetric_mels: True\n",
            "  tacotron_adam_beta1: 0.9\n",
            "  tacotron_adam_beta2: 0.999\n",
            "  tacotron_adam_epsilon: 1e-06\n",
            "  tacotron_batch_size: 32\n",
            "  tacotron_decay_learning_rate: True\n",
            "  tacotron_decay_rate: 0.4\n",
            "  tacotron_decay_steps: 50000\n",
            "  tacotron_dropout_rate: 0.5\n",
            "  tacotron_final_learning_rate: 1e-05\n",
            "  tacotron_initial_learning_rate: 0.001\n",
            "  tacotron_reg_weight: 1e-06\n",
            "  tacotron_scale_regularization: True\n",
            "  tacotron_start_decay: 50000\n",
            "  tacotron_teacher_forcing_ratio: 1.0\n",
            "  tacotron_zoneout_rate: 0.1\n",
            "  trim_silence: True\n",
            "  use_vae: True\n",
            "  vae_dim: 32\n",
            "  vae_warming_up: 15000\n",
            "  vae_weight_multiler: 0.002\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:63: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "Loaded metadata for 13100 examples (23.94 hours)\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/feeder.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/feeder.py:57: The name tf.FIFOQueue is deprecated. Please use tf.queue.FIFOQueue instead.\n",
            "\n",
            "no step_counter file found, assuming there is no saved checkpoint\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/tacotron.py:52: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/zoneout_LSTM.py:88: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:54: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv1D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:55: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:58: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:132: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/zoneout_LSTM.py:145: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:64: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:37: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:18: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:21: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/attention.py:161: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/attention.py:164: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/modules.py:196: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "Initialized Tacotron model. Dimensions (? = dynamic shape): \n",
            "  embedding:                (?, ?, 512)\n",
            "  enc conv out:             (?, ?, 512)\n",
            "  encoder out:              (?, ?, 512)\n",
            "  decoder out:              (?, ?, 80)\n",
            "  residual out:             (?, ?, 512)\n",
            "  projected residual out:   (?, ?, 80)\n",
            "  mel out:                  (?, ?, 80)\n",
            "  <stop_token> out:         (?, ?)\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/tacotron.py:207: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/tacotron.py:233: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/tacotron.py:297: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/tacotron.py:267: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/tacotron.py:277: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/models/tacotron.py:277: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:21: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:23: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:36: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:90: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:93: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:97: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:99: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/VAE_Tacotron2/tacotron/train.py:100: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2020-01-10 15:32:06.369014: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 29360128 exceeds 10% of system memory.\n",
            "2020-01-10 15:32:06.387803: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 29360128 exceeds 10% of system memory.\n",
            "2020-01-10 15:32:06.394311: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of system memory.\n",
            "2020-01-10 15:32:06.403533: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of system memory.\n",
            "2020-01-10 15:32:06.458551: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 29360128 exceeds 10% of system memory.\n",
            "No model to load at ./logs-Tacotron/pretrained/\n",
            "\n",
            "Generated 32 batches of size 32 in 40.273 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.821 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.912 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.106 sec\n",
            "Step     100 [3.808 sec/step, loss=0.92298, avg_loss=2.17319]\n",
            "Writing summary at step: 100\n",
            "\n",
            "Generated 32 batches of size 32 in 38.008 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.014 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.406 sec\n",
            "Step     200 [3.256 sec/step, loss=0.64055, avg_loss=0.78203]\n",
            "Writing summary at step: 200\n",
            "\n",
            "Generated 32 batches of size 32 in 37.123 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.115 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.116 sec\n",
            "Step     300 [3.296 sec/step, loss=0.54458, avg_loss=0.61688]\n",
            "Writing summary at step: 300\n",
            "\n",
            "Generated 32 batches of size 32 in 39.616 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.810 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 36.832 sec\n",
            "Step     400 [3.444 sec/step, loss=0.47260, avg_loss=0.57024]\n",
            "Writing summary at step: 400\n",
            "\n",
            "Generated 32 batches of size 32 in 32.109 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 35.015 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.231 sec\n",
            "Step     500 [3.199 sec/step, loss=0.48799, avg_loss=0.52077]\n",
            "Writing summary at step: 500\n",
            "Saving checkpoint to: ./logs-Tacotron/pretrained/model.ckpt-500\n",
            "Saving alignment, Mel-Spectrograms and griffin-lim inverted waveform..\n",
            "Input at step 500: The lad in question was found in Coldbath Fields prison, to which he had been sent for a month in default of paying a fine of forty shillings.~______________________\n",
            "\n",
            "Generated 32 batches of size 32 in 39.621 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.717 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.131 sec\n",
            "Step     600 [3.304 sec/step, loss=0.46431, avg_loss=0.53903]\n",
            "Writing summary at step: 600\n",
            "\n",
            "Generated 32 batches of size 32 in 37.830 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.917 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.729 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.312 sec\n",
            "Step     700 [3.329 sec/step, loss=0.37982, avg_loss=0.52454]\n",
            "Writing summary at step: 700\n",
            "\n",
            "Generated 32 batches of size 32 in 37.725 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.214 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 35.930 sec\n",
            "Step     800 [3.251 sec/step, loss=0.36089, avg_loss=0.50415]\n",
            "Writing summary at step: 800\n",
            "\n",
            "Generated 32 batches of size 32 in 33.734 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.004 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.529 sec\n",
            "Step     900 [3.291 sec/step, loss=0.43486, avg_loss=0.49510]\n",
            "Writing summary at step: 900\n",
            "\n",
            "Generated 32 batches of size 32 in 38.120 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.913 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.234 sec\n",
            "Step    1000 [3.146 sec/step, loss=0.42602, avg_loss=0.48568]\n",
            "Writing summary at step: 1000\n",
            "Saving checkpoint to: ./logs-Tacotron/pretrained/model.ckpt-1000\n",
            "Saving alignment, Mel-Spectrograms and griffin-lim inverted waveform..\n",
            "Input at step 1000: He was fond of restoring the ruined temples of the old Babylonian cities,~____________\n",
            "\n",
            "Generated 32 batches of size 32 in 38.613 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.922 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.524 sec\n",
            "Step    1100 [3.318 sec/step, loss=0.41225, avg_loss=0.48052]\n",
            "Writing summary at step: 1100\n",
            "\n",
            "Generated 32 batches of size 32 in 38.605 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.727 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.824 sec\n",
            "Step    1200 [3.309 sec/step, loss=0.40685, avg_loss=0.47488]\n",
            "Writing summary at step: 1200\n",
            "\n",
            "Generated 32 batches of size 32 in 34.531 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 33.939 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.131 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.726 sec\n",
            "Step    1300 [3.310 sec/step, loss=0.40232, avg_loss=0.46683]\n",
            "Writing summary at step: 1300\n",
            "\n",
            "Generated 32 batches of size 32 in 37.911 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.725 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.217 sec\n",
            "Step    1400 [3.342 sec/step, loss=0.39038, avg_loss=0.46347]\n",
            "Writing summary at step: 1400\n",
            "\n",
            "Generated 32 batches of size 32 in 38.615 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.735 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.113 sec\n",
            "Step    1500 [3.364 sec/step, loss=0.39538, avg_loss=0.45585]\n",
            "Writing summary at step: 1500\n",
            "Saving checkpoint to: ./logs-Tacotron/pretrained/model.ckpt-1500\n",
            "Saving alignment, Mel-Spectrograms and griffin-lim inverted waveform..\n",
            "Input at step 1500: Shelley denied seeing Oswald after twelve noon or at any time after the shooting.~______________\n",
            "\n",
            "Generated 32 batches of size 32 in 37.923 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.212 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.410 sec\n",
            "Step    1600 [3.367 sec/step, loss=0.38932, avg_loss=0.46100]\n",
            "Writing summary at step: 1600\n",
            "\n",
            "Generated 32 batches of size 32 in 33.416 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 35.333 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.009 sec\n",
            "Step    1700 [3.262 sec/step, loss=0.38645, avg_loss=0.45628]\n",
            "Writing summary at step: 1700\n",
            "\n",
            "Generated 32 batches of size 32 in 38.212 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.311 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.334 sec\n",
            "Step    1800 [3.322 sec/step, loss=0.38063, avg_loss=0.45688]\n",
            "Writing summary at step: 1800\n",
            "\n",
            "Generated 32 batches of size 32 in 38.017 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.215 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.716 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.308 sec\n",
            "Step    1900 [3.418 sec/step, loss=0.37311, avg_loss=0.45552]\n",
            "Writing summary at step: 1900\n",
            "\n",
            "Generated 32 batches of size 32 in 37.534 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 37.146 sec\n",
            "\n",
            "Generated 32 batches of size 32 in 38.018 sec\n",
            "Step    2000 [3.219 sec/step, loss=0.36698, avg_loss=0.45823]\n",
            "Writing summary at step: 2000\n",
            "Saving checkpoint to: ./logs-Tacotron/pretrained/model.ckpt-2000\n",
            "Saving alignment, Mel-Spectrograms and griffin-lim inverted waveform..\n",
            "Input at step 2000: Fischer testified that about ten or fifteen seconds before the motorcade turned onto Houston Street from Main Street,~_________________________\n",
            "\n",
            "Generated 32 batches of size 32 in 33.526 sec\n",
            "2020-01-10 17:26:20.993102: W tensorflow/core/kernels/queue_base.cc:277] _0_datafeeder/input_queue: Skipping cancelled enqueue attempt with queue not closed\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 33, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 27, in main\n",
            "    tacotron_train(args)\n",
            "  File \"/content/VAE_Tacotron2/tacotron/train.py\", line 203, in tacotron_train\n",
            "    train(log_dir, args)\n",
            "  File \"/content/VAE_Tacotron2/tacotron/train.py\", line 126, in train\n",
            "    step, loss, opt = sess.run([global_step, model.loss, model.optimize])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
            "\t [[{{node datafeeder/input_queue_enqueue}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/VAE_Tacotron2/tacotron/feeder.py\", line 74, in run\n",
            "    self._enqueue_next_group()\n",
            "  File \"/content/VAE_Tacotron2/tacotron/feeder.py\", line 95, in _enqueue_next_group\n",
            "    self._session.run(self._enqueue_op, feed_dict=feed_dict)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
            "\t [[node datafeeder/input_queue_enqueue (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "\n",
            "Original stack trace for 'datafeeder/input_queue_enqueue':\n",
            "  File \"train.py\", line 33, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 27, in main\n",
            "    tacotron_train(args)\n",
            "  File \"/content/VAE_Tacotron2/tacotron/train.py\", line 203, in tacotron_train\n",
            "    train(log_dir, args)\n",
            "  File \"/content/VAE_Tacotron2/tacotron/train.py\", line 64, in train\n",
            "    feeder = Feeder(coord, input_path, hparams)\n",
            "  File \"/content/VAE_Tacotron2/tacotron/feeder.py\", line 58, in __init__\n",
            "    self._enqueue_op = queue.enqueue(self._placeholders)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/data_flow_ops.py\", line 346, in enqueue\n",
            "    self._queue_ref, vals, name=scope)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_data_flow_ops.py\", line 4410, in queue_enqueue_v2\n",
            "    timeout_ms=timeout_ms, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
            "    attrs, op_def, compute_device)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}